# ðŸš— Secure Crash Data Systems Using Explainable AI in Smart Transportation

**Project Title**: Cybersecurity, Data Integrity, and Explainable AI in Smart Transportation Systems for Crash Data Analysis and Public Safety  
**Author**: Ibrahim Suleiman | [GitHub](https://github.com/Isuleim)

---

## ðŸ“Œ Project Overview
This research investigates how secure, explainable systems can protect the reliability of crash data in smart cities. As transportation networks become increasingly connected, ensuring the security and interpretability of crash prediction systems is vital for emergency response, policymaking, and public safety.

---

## ðŸŽ¯ Objectives
- Design tamper-proof systems for real-time crash data
- Use blockchain to log immutable crash events
- Apply SHAP, LIME, and attention models for explainable crash prediction
- Simulate adversarial attacks on transportation networks
- Build edge AI models that preserve privacy using federated learning

---

## ðŸ› ï¸ Tools & Technologies
- `IoT Crash Sensors` â€“ Vehicle & roadside device integration
- `Encrypted MQTT / TLS` â€“ Secure IoT communication
- `Blockchain` â€“ Tamper-resistant crash logging
- `SHAP / LIME / Attention Models` â€“ Explainability
- `Edge/Federated Learning` â€“ Privacy-respecting modeling
- `Adversarial Testing` â€“ Evaluate robustness

---

## ðŸ›¡ï¸ Background
My experience as a Codes Program Consultant with the Georgia Department of Public Health revealed how essential reliable crash data is for highway safety strategy. This project builds on that by enhancing **data trust, model interpretability, and privacy**.

---

## ðŸŒ Broader Impact
This work supports safer transportation systems and responsible policymaking by strengthening **data integrity, privacy, and AI transparency** in critical infrastructure.

> _"AI for Safety. Security for All. Data You Can Trust."_
